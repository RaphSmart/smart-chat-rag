{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7753b7-74aa-427a-9c02-e50c6041a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Project root = one level above notebooks\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "# allows imports from src\n",
    "sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "607b68b8-fdff-471e-b7a9-e7ad5e5c35af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raphsmart/Desktop/Projects/Retrieval_Augmented_Generation_System/doc-chat-rag/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Calling modules from src folder for testing\n",
    "from src.ingestion.chunking import chunk_text\n",
    "from src.embeddings.embedder import Embedder\n",
    "from src.retrieval.faiss_store import FaissStore\n",
    "from src.llm.local_llm import LocalLLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9580cb6-3310-493a-9641-9afd07f0be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling modules from src folder for testing\n",
    "\n",
    "sample_text = \"\"\"\n",
    "Customers can request a refund within 30 days of purchase.\n",
    "The item must be unused and returned in its original packaging.\n",
    "Refunds are processed within 5 business days.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7b0bad-0f7b-4246-9702-e0236a41562d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 1\n"
     ]
    }
   ],
   "source": [
    "# Calling modules from src folder for testing\n",
    "chunks = chunk_text(sample_text)\n",
    "print(\"Number of chunks:\", len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f43b901-037a-4382-b972-cc2cf0d95547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|█| 103/103 [00:00<00:00, 591.80it\n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Batches: 100%|███████████| 1/1 [00:00<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings\n",
    "embedder = Embedder()\n",
    "\n",
    "chunk_embeddings = embedder.embed(chunks)\n",
    "print(chunk_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad4e54e1-91af-4388-b5cb-f9f588127493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store & retrieve with FAISS\n",
    "\n",
    "store = FaissStore(embedding_dim=chunk_embeddings.shape[1])\n",
    "store.add(chunk_embeddings, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2c24164-987f-44cf-95d5-9be2892cfb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████| 1/1 [00:00<00:00,  7.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\nCustomers can request a refund within 30 days of purchase.\\nThe item must be unused and returned in its original packaging.\\nRefunds are processed within 5 business days.\\n',\n",
       " '\\nCustomers can request a refund within 30 days of purchase.\\nThe item must be unused and returned in its original packaging.\\nRefunds are processed within 5 business days.\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the refund policy\"\n",
    "\n",
    "query_embedding = embedder.embed([query])\n",
    "retrieved_chunks = store.search(query_embedding, k=2)\n",
    "\n",
    "retrieved_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26053ebb-6738-4831-a64e-d586d0ddaef6",
   "metadata": {},
   "source": [
    "Generate answer with Local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d4ec92b-de9f-4985-aadf-8e2e57720d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\\n\".join(retrieved_chunks)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the question using ONLY the context below.\n",
    "If the answer is not in the context, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad9c94-e5d7-4288-b2a0-cacbba6527a2",
   "metadata": {},
   "source": [
    "Load LLM (path-safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc746fcb-192f-4dae-a4ca-b710302197d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_metal_init: skipping kernel_soft_max_f16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_soft_max_f16_4                    (not supported)\n",
      "ggml_metal_init: skipping kernel_soft_max_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_soft_max_f32_4                    (not supported)\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_rms_norm                          (not supported)\n",
      "ggml_metal_init: skipping kernel_rms_norm_mul                      (not supported)\n",
      "ggml_metal_init: skipping kernel_rms_norm_mul_add                  (not supported)\n",
      "ggml_metal_init: skipping kernel_l2_norm                           (not supported)\n",
      "ggml_metal_init: skipping kernel_group_norm                        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f32_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f16_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f16_f32_1row               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f16_f32_l4                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f16_f16                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q4_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q4_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q5_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q5_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q8_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_mxfp4_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_f16_f32_r1_2           (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_f16_f32_r1_3           (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_f16_f32_r1_4           (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_f16_f32_r1_5           (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_0_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_0_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_0_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_0_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_1_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_1_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_1_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_1_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_0_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_0_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_0_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_0_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_1_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_1_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_1_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_1_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q8_0_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q8_0_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q8_0_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q8_0_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_mxfp4_f32_r1_2         (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_mxfp4_f32_r1_3         (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_mxfp4_f32_r1_4         (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_mxfp4_f32_r1_5         (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_K_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_K_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_K_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_K_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_K_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_K_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_K_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_K_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q6_K_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q6_K_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q6_K_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q6_K_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_iq4_nl_f32_r1_2        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_iq4_nl_f32_r1_3        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_iq4_nl_f32_r1_4        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_iq4_nl_f32_r1_5        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q2_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q3_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q4_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q5_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q6_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq2_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq2_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq3_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq3_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq2_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq1_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq1_m_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq4_nl_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq4_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_f32_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_f16_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q4_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q4_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q5_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q5_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q8_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_mxfp4_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q2_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q3_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q4_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q5_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q6_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq2_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq2_xs_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq3_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq3_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq2_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq1_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq1_m_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq4_nl_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq4_xs_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_f32_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_f16_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q8_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_mxfp4_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_mxfp4_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q2_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q3_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q6_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_m_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_nl_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_map0_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_map1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f32_f16                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f16_f16                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_0_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_1_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_0_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_1_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q8_0_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_mxfp4_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q2_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q3_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q6_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xxs_f16             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xs_f16              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_xxs_f16             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_s_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_s_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_s_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_m_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_nl_f16              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_xs_f16              (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h64            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h80            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h96            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h112           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h128           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h192           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_hk192_hv128    (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h256           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_hk576_hv512    (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h64        (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h96        (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h128       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h192       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h256       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = PROJECT_ROOT / \"models\" / \"phi-2.gguf\"\n",
    "\n",
    "llm = LocalLLM(model_path=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37af0fa8-5f0b-4a1c-887b-e32b61adee86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refunds are processed within 5 business days.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = llm.generate(prompt)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfca5b99-cde4-4a44-9ee0-d653623f8a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|█| 103/103 [00:00<00:00, 466.21it\n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "ggml_metal_init: skipping kernel_soft_max_f16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_soft_max_f16_4                    (not supported)\n",
      "ggml_metal_init: skipping kernel_soft_max_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_soft_max_f32_4                    (not supported)\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_rms_norm                          (not supported)\n",
      "ggml_metal_init: skipping kernel_rms_norm_mul                      (not supported)\n",
      "ggml_metal_init: skipping kernel_rms_norm_mul_add                  (not supported)\n",
      "ggml_metal_init: skipping kernel_l2_norm                           (not supported)\n",
      "ggml_metal_init: skipping kernel_group_norm                        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f32_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f16_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f16_f32_1row               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f16_f32_l4                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f16_f16                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q4_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q4_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q5_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q5_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q8_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_mxfp4_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_f16_f32_r1_2           (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_f16_f32_r1_3           (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_f16_f32_r1_4           (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_f16_f32_r1_5           (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_0_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_0_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_0_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_0_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_1_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_1_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_1_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_1_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_0_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_0_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_0_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_0_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_1_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_1_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_1_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_1_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q8_0_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q8_0_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q8_0_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q8_0_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_mxfp4_f32_r1_2         (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_mxfp4_f32_r1_3         (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_mxfp4_f32_r1_4         (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_mxfp4_f32_r1_5         (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_K_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_K_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_K_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_K_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_K_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_K_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_K_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_K_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q6_K_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q6_K_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q6_K_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q6_K_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_iq4_nl_f32_r1_2        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_iq4_nl_f32_r1_3        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_iq4_nl_f32_r1_4        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_iq4_nl_f32_r1_5        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q2_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q3_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q4_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q5_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q6_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq2_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq2_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq3_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq3_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq2_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq1_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq1_m_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq4_nl_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq4_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_f32_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_f16_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q4_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q4_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q5_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q5_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q8_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_mxfp4_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q2_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q3_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q4_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q5_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q6_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq2_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq2_xs_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq3_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq3_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq2_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq1_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq1_m_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq4_nl_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq4_xs_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_f32_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_f16_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q8_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_mxfp4_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_mxfp4_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q2_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q3_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q6_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_m_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_nl_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_map0_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_map1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f32_f16                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f16_f16                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_0_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_1_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_0_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_1_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q8_0_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_mxfp4_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q2_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q3_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q6_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xxs_f16             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xs_f16              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_xxs_f16             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_s_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_s_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_s_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_m_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_nl_f16              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_xs_f16              (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h64            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h80            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h96            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h112           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h128           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h192           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_hk192_hv128    (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h256           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_hk576_hv512    (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h64        (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h96        (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h128       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h192       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h256       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "Batches: 100%|███████████| 1/1 [00:00<00:00,  5.44it/s]\n",
      "Batches: 100%|███████████| 1/1 [00:00<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Customers can request a refund within 30 days of purchase. The item must be unused and returned in its original packaging.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from src.pipeline import RAGPipeline\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "MODEL_PATH = PROJECT_ROOT / \"models\" / \"phi-2.gguf\"\n",
    "\n",
    "pipeline = RAGPipeline(model_path=MODEL_PATH)\n",
    "\n",
    "docs = [\n",
    "    \"\"\"\n",
    "    Customers can request a refund within 30 days of purchase.\n",
    "    The item must be unused and returned in its original packaging.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "pipeline.ingest(docs)\n",
    "\n",
    "answer = pipeline.query(\"What is the refund policy?\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83ed6d3c-93f5-44f3-b024-af6b65e29262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Batches: 100%|███████████| 1/1 [00:00<00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.ingest(docs)\n",
    "answer = pipeline.query(\"What is the refund policy?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf46781-eaee-448b-8ed0-9923421eadc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "196732fb-5322-43a8-b0eb-bb9b558180d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06f4f8-bea3-41ff-b48c-17f78614292d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20ddd613-6dba-44be-baf2-c9c1b4f06083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|█| 103/103 [00:00<00:00, 494.68it\n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8731a1fc-2d68-4694-9995-359669cb814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I love this product\",\n",
    "    \"This item is amazing\",\n",
    "    \"I hate this product\",\n",
    "    \"The weather is sunny today\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9270303-d2a9-418c-8534-faccb9e7b449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 384)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate embeddings\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f61f4ed6-4cb3-440f-bb9b-96e347455754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate chunking using plain text\n",
    "text = \"\"\"\n",
    "Refund Policy:\n",
    "Customers can request a refund within 30 days of purchase.\n",
    "The item must be unused and in original packaging.\n",
    "\n",
    "Shipping Policy:\n",
    "Orders are shipped within 2–3 business days.\n",
    "Delivery time depends on location.\n",
    "\n",
    "Privacy Policy:\n",
    "We do not share customer data with third parties.\n",
    "Personal information is stored securely.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e9fc3c4-08c6-412e-a991-a1757b589e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=100, overlap=20):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = start + chunk_size\n",
    "        chunk = words[start:end]\n",
    "        chunks.append(\" \".join(chunk))\n",
    "        start += chunk_size - overlap\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddb8ed32-23f0-4b65-a133-bbea0fa1830f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 1 ---\n",
      "Refund Policy: Customers can request a refund within 30 days of purchase. The item must be unused and in original packaging. Shipping Policy: Orders are shipped within 2–3 business days. Delivery time depends on location. Privacy Policy: We do not\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Delivery time depends on location. Privacy Policy: We do not share customer data with third parties. Personal information is stored securely.\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_text(text, chunk_size=40, overlap=10)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"\\n--- Chunk {i+1} ---\")\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0541594f-b73c-42bb-aeae-7241a7add58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|█| 103/103 [00:00<00:00, 473.53it\n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 384)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "chunk_embeddings = model.encode(chunks)\n",
    "chunk_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdf4111-7b27-4348-89ad-5c20fa323799",
   "metadata": {},
   "source": [
    "#### Implement FAISS\n",
    "FAISS is very fast math\n",
    "    optimized similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eddab681-f654-4906-ac0a-a8d55b5c4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAISS index\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "dimension = chunk_embeddings.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(chunk_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dec7ca0-64b4-475a-888e-e15671abff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the refund policy?\"\n",
    "\n",
    "query_embedding = model.encode([query])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "801820c2-9d89-4b75-90f7-6b30f7122a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search\n",
    "# Number of chunks to retrieve\n",
    "k = 2\n",
    "\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d83f86da-6d86-4665-b4d8-68b8e0a28345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Retrieved Chunk ---\n",
      "Refund Policy: Customers can request a refund within 30 days of purchase. The item must be unused and in original packaging. Shipping Policy: Orders are shipped within 2–3 business days. Delivery time depends on location. Privacy Policy: We do not\n",
      "\n",
      "--- Retrieved Chunk ---\n",
      "Delivery time depends on location. Privacy Policy: We do not share customer data with third parties. Personal information is stored securely.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve text\n",
    "\n",
    "for idx in indices[0]:\n",
    "    print(\"\\n--- Retrieved Chunk ---\")\n",
    "    print(chunks[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f388ad-d671-472f-b96a-15f9ab42e606",
   "metadata": {},
   "source": [
    "### Hugging Face Inference call for FLAN-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e338334-04cc-430a-8105-adcbadb09814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7452f247-9d1a-40c2-b7a7-d614879609ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt from retrieved chunks\n",
    "\n",
    "context = \"\\n\\n\".join([chunks[idx] for idx in indices[0]])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the question using ONLY the context below.\n",
    "If the answer is not in the context, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3245fbb-1673-4e23-a16e-79181cf43fae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7567c070-1aac-467a-991f-e0d8a49445af",
   "metadata": {},
   "source": [
    "### Generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "168fd045-bd17-4d6b-b62b-388d31fba0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "{'error': 'https://api-inference.huggingface.co is no longer supported. Please use https://router.huggingface.co instead.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "MODEL_ID = \"google/flan-t5-large\"\n",
    "\n",
    "API_URL = f\"https://api-inference.huggingface.co/models/{MODEL_ID}\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {HF_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 200,\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6227f2cf-3d81-4118-b553-69fab78e61fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "\n",
    "MODEL_PATH = PROJECT_ROOT / \"models\" / \"phi-2.gguf\"\n",
    "\n",
    "# print(MODEL_PATH)\n",
    "print(MODEL_PATH.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24d560bb-e204-4da7-9562-b2322c8733fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_metal_init: skipping kernel_soft_max_f16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_soft_max_f16_4                    (not supported)\n",
      "ggml_metal_init: skipping kernel_soft_max_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_soft_max_f32_4                    (not supported)\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_rms_norm                          (not supported)\n",
      "ggml_metal_init: skipping kernel_rms_norm_mul                      (not supported)\n",
      "ggml_metal_init: skipping kernel_rms_norm_mul_add                  (not supported)\n",
      "ggml_metal_init: skipping kernel_l2_norm                           (not supported)\n",
      "ggml_metal_init: skipping kernel_group_norm                        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f32_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f16_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f16_f32_1row               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f16_f32_l4                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_f16_f16                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q4_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q4_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q5_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q5_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q8_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_mxfp4_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_f16_f32_r1_2           (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_f16_f32_r1_3           (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_f16_f32_r1_4           (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_f16_f32_r1_5           (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_0_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_0_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_0_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_0_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_1_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_1_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_1_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_1_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_0_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_0_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_0_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_0_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_1_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_1_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_1_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_1_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q8_0_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q8_0_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q8_0_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q8_0_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_mxfp4_f32_r1_2         (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_mxfp4_f32_r1_3         (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_mxfp4_f32_r1_4         (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_mxfp4_f32_r1_5         (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_K_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_K_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_K_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q4_K_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_K_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_K_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_K_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q5_K_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q6_K_f32_r1_2          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q6_K_f32_r1_3          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q6_K_f32_r1_4          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_q6_K_f32_r1_5          (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_iq4_nl_f32_r1_2        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_iq4_nl_f32_r1_3        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_iq4_nl_f32_r1_4        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_ext_iq4_nl_f32_r1_5        (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q2_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q3_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q4_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q5_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_q6_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq2_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq2_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq3_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq3_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq2_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq1_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq1_m_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq4_nl_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_iq4_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_f32_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_f16_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q4_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q4_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q5_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q5_1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q8_0_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_mxfp4_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q2_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q3_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q4_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q5_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_q6_K_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq2_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq2_xs_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq3_xxs_f32             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq3_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq2_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq1_s_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq1_m_f32               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq4_nl_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_iq4_xs_f32              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_f32_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_f16_f32                    (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_1_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q8_0_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_mxfp4_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_mxfp4_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q2_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q3_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q4_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q5_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_q6_K_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_xxs_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq3_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq2_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_s_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq1_m_f32                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_nl_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_iq4_xs_f32                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_map0_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_map1_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f32_f16                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_f16_f16                 (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_0_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_1_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_0_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_1_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q8_0_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_mxfp4_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q2_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q3_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q4_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q5_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_q6_K_f16                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xxs_f16             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_xs_f16              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_xxs_f16             (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq3_s_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq2_s_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_s_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq1_m_f16               (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_nl_f16              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_iq4_xs_f16              (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h64            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h80            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h96            (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h112           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h128           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h192           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_hk192_hv128    (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_h256           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_f16_hk576_hv512    (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_0_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q4_1_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_0_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q5_1_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_q8_0_hk576_hv512   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h64        (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h64       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h96        (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h96       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h128       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h192       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h192      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_hk192_hv128 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_h256       (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_f16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_0_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q4_1_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_0_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q5_1_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_q8_0_hk576_hv512 (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=str(MODEL_PATH),\n",
    "    n_ctx=2048,\n",
    "    n_threads=4,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddf2f2ab-53bb-4936-bcd3-9f291a292840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm(\"What is retrieval augmented generation?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a617d422-6f87-4633-8161-2cdb97e73bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\\n\".join([chunks[idx] for idx in indices[0]])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer the question using ONLY the context below.\n",
    "If the answer is not in the context, say \"I don't know\".\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e38cf571-8cb9-4387-bde1-f04e8891295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within 30 days of purchase, customers can request a refund.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = llm(prompt, max_tokens=256)\n",
    "answer = output[\"choices\"][0][\"text\"]\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74bbcd51-de9c-4c9d-a26a-7e6e91ac39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(llm(\"Give a short definition of RAG.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65d66092-9bbb-4c8a-a892-7e4463bd637b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to test, need to be removed\n",
    "\n",
    "from src.ingestion.chunking import chunk_text\n",
    "\n",
    "chunks = chunk_text(\"This is a test document.\" * 50)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d5705-9704-466d-b555-20536c128189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (doc-chat-rag)",
   "language": "python",
   "name": "doc-chat-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
